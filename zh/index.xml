<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>蒋超康的个人主页</title>
    <link>https://jiangchaokang.github.io/zh/</link>
      <atom:link href="https://jiangchaokang.github.io/zh/index.xml" rel="self" type="application/rss+xml" />
    <description>蒋超康的个人主页</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>zh-Hans</language><lastBuildDate>Fri, 01 Dec 2017 00:00:00 +0800</lastBuildDate>
    <image>
      <url>https://jiangchaokang.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>蒋超康的个人主页</title>
      <link>https://jiangchaokang.github.io/zh/</link>
    </image>
    
    <item>
      <title>SFGAN: Unsupervised Generative Adversarial Learning of 3D Scene Flow from the 3D Scene Self</title>
      <link>https://jiangchaokang.github.io/zh/publication/SFGAN-Unsupervised-Generative-Adversarial-Learning-of-3D-Scene-Flow-from-the-3D-Scene-Self/</link>
      <pubDate>Sat, 13 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://jiangchaokang.github.io/zh/publication/SFGAN-Unsupervised-Generative-Adversarial-Learning-of-3D-Scene-Flow-from-the-3D-Scene-Self/</guid>
      <description></description>
    </item>

    
    <item>
      <title>国家自然科学基金 “自学习的机器人动态场景感知”</title>
      <link>https://jiangchaokang.github.io/zh/project/restaurant_robot/</link>
      <pubDate>Sat, 15 Sep 2018 00:00:00 +0000</pubDate>
      <guid>https://jiangchaokang.github.io/zh/project/restaurant_robot/</guid>
      <description>&lt;p&gt;2020-11-01 ~ 2022-07-01  本项目部分得到中央高校基本科研业务费专项资金2020ZDPY0303，部分得到上海市教委和上海市“曙光”项目的资助。教育发展基金19SG08，部分由深圳市科技计划项目JSGG20201103094400002资助，部分由上海市科委21511101900资助，部分由英伟达公司资助。3D场景流表征当前时间点如何在3D欧几里得空间中流向下一个时间点，具有自主推断场景中所有对象的非刚性运动的能力。目前最先进的3D动态场景感知都比较依赖类似于LiDAR等传感器。KITTI 数据集中使用的彩色相机成本不超过 20 美元，而 Velodyne HDL-64E LiDAR 传感器的成本约为 75,000 美元 [16] 自动驾驶或机器人技术的硬件成本将因此大大降低。立体相机系统可以为基于 LiDAR 的场景流估计方案提供低成本的备份系统。具体负责内容如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;统筹规划送餐机器人的机械结构设计、电路设计、定位建图、规划控制，进行任务分工与项目时间管理；&lt;/li&gt;
&lt;li&gt;个人负责送餐机器人的上位机功能实现，包括上下位机通信、单线激光雷达建图定位、路径规划及控制；&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>News</title>
      <link>https://jiangchaokang.github.io/zh/news/</link>
      <pubDate>Fri, 01 Dec 2017 00:00:00 +0800</pubDate>
      <guid>https://jiangchaokang.github.io/zh/news/</guid>
      <description>








&lt;p&gt;&lt;strong&gt;[2021.11]&lt;/strong&gt; &lt;a href=&#34;https://jiangchaokang.github.io/en/publication/SFGAN-Unsupervised-Generative-Adversarial-Learning-of-3D-Scene-Flow-from-the-3D-Scene-Self&#34;&gt;一篇论文&lt;/a&gt; 被 Advanced Intelligent Systems 接收。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;[2021.02]&lt;/strong&gt; &lt;a href=&#34;https://jiangchaokang.github.io/en/publication/rangeioudet-range-image-based-real-time-3d-object-detector-optimized-by-intersection-over-union&#34;&gt;一篇论文&lt;/a&gt; 被 CVPR 2021 Oral 接收。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;[2021.02]&lt;/strong&gt; &lt;a href=&#34;https://jiangchaokang.github.io/en/publication/centroidreg-a-global-to-local-framework-for-partial-point-cloud-registration&#34;&gt;一篇论文&lt;/a&gt; 被 IEEE Robotics and Automation Letters (ICRA 2021 option) 接收。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;[2020.09]&lt;/strong&gt; 我们的方法 &lt;a href=&#34;https://jiangchaokang.github.io/en/publication/rangercnn-towards-fast-and-accurate-3d-object-detection-with-range-image-representation&#34;&gt;RangeRCNN&lt;/a&gt; 在 &lt;a href=&#34;http://www.cvlibs.net/datasets/kitti/eval_3dobject.php&#34;&gt;KITTI 3D车辆检测&lt;/a&gt; 中排名第二 （在有论文的方法中）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;[2020.07]&lt;/strong&gt; 我们的方法 &lt;strong&gt;HRI-MSP-L&lt;/strong&gt; 在 &lt;a href=&#34;http://www.cvlibs.net/datasets/kitti/eval_3dobject.php&#34;&gt;KITTI Cyclist检测 benchmark&lt;/a&gt; 取得四项任务第一 (2D检测, 3D检测, BEV检测, 朝向检测)。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;[2020.06]&lt;/strong&gt; &lt;a href=&#34;https://jiangchaokang.github.io/en/publication/3d-instance-embedding-learning-with-a-structure-aware-loss-function-for-point-cloud-segmentation&#34;&gt;一篇论文&lt;/a&gt; 被 IEEE Robotics and Automation Letters (IROS 2020 option) 接收。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;[2020.01]&lt;/strong&gt; &lt;a href=&#34;https://jiangchaokang.github.io/en/publication/fusing-geometrical-and-visual-information-via-superpoints-for-the-semantic-segmentation-of-3d-road-scenes/&#34;&gt;一篇论文&lt;/a&gt; 被 Tsinghua Science and Technology 接收。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;[2019.02]&lt;/strong&gt; 我们的方法 &lt;a href=&#34;https://jiangchaokang.github.io/en/publication/3d-instance-embedding-learning-with-a-structure-aware-loss-function-for-point-cloud-segmentation&#34;&gt;SALoss&lt;/a&gt; 在 &lt;a href=&#34;http://kaldir.vc.in.tum.de/scannet_benchmark&#34;&gt;ScanNet benchmark&lt;/a&gt; (3D实例分割任务)中取得第一。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;[2019.01]&lt;/strong&gt; &lt;a href=&#34;https://jiangchaokang.github.io/en/publication/hierarchical-depthwise-graph-convolutional-neural-network-for-3d-semantic-segmentation-of-point-clouds&#34;&gt;一篇论文&lt;/a&gt; 被 ICRA 2019 接收。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;[2018.09]&lt;/strong&gt; 我们的方法 &lt;a href=&#34;https://jiangchaokang.github.io/en/publication/hierarchical-depthwise-graph-convolutional-neural-network-for-3d-semantic-segmentation-of-point-clouds&#34;&gt;HDGCN&lt;/a&gt; 在 &lt;a href=&#34;https://npm3d.fr/paris-lille-3d&#34;&gt;Paris-Lille-3D benchmark&lt;/a&gt; (3D语义分割任务) 中取得第一。&lt;/p&gt;

</description>
    </item>
    
    <item>
      <title>除草机器人</title>
      <link>https://jiangchaokang.github.io/zh/project/internal-project/</link>
      <pubDate>Thu, 30 Nov 2017 00:00:00 +0000</pubDate>
      <guid>https://jiangchaokang.github.io/zh/project/internal-project/</guid>
      <description>&lt;p&gt;2021-10-01 ~ 2022-10-01  除草机器人项目共包含AI视觉障碍物分类识别、多传感器离线与在线标定、视觉惯性里程计、基于多传感器融合的全局位姿估计、基于激光雷达和深度相机的障碍物检测技术以及多传感器融合的3D障碍物检测技术。项目中主要负责基于RGB（色彩纹理）与激光雷达（几何）融合的3D障碍物检测技术。具体负责内容如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;负责无人车系统集成，包括集成视觉目标检测、车道线检测、信号灯检测、激光雷达检测、车辆定位、决策、路径规划、车辆控制等子模块，协调各子模块负责人定义功能接口及进行真车联合调试；&lt;/li&gt;
&lt;li&gt;负责无人车决策、局部路径规划及车辆速度控制模块的开发与完善，实现无人车高速及城区道路的正常行驶；&lt;/li&gt;
&lt;li&gt;负责参加2017年中国智能车未来挑战赛，作为比赛过程中的唯一跟车负责人，实时跟进并负责解决比赛过程中的突发状况；&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
